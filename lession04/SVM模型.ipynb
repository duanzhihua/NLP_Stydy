{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "\n",
    "SVM的英文全称是Support Vector Machines，我们叫它支持向量机。支持向量机是我们用于分类的一种算法\n",
    "\n",
    "## SVM原理\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "SVM 的核心思想是尽最大的努力使分开的两个类别有最大间隔，这样才使得分割具有更高的可信度。而且对于未知的新样本才有很好的分类预测能力。那么怎么描述这个间隔，并且让它最大呢？SVM 的办法是：让离分隔面最近的数据点具有最大的距离。\n",
    "\n",
    "不同方向的最优决策面的分类间隔通常是不同的，那个具有“最大间隔”的决策面就是SVM要寻找的最优解。而这个真正的最优解对应的两侧虚线所穿过的样本点，就是SVM中的支持样本点，称为”支持向量”\n",
    "\n",
    "超平面、约束条件、最优化目标函数、对偶转换（拉格朗日）、KKT\n",
    "\n",
    "SMO\n",
    "\n",
    "核函数就是通过非线性化映射在较高维度进行的线性化分割使得相当于在原本维度作了一个非线性化分割。\n",
    "\n",
    "https://blog.csdn.net/weixin_39605679/article/details/81170300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## SVM文本分类\n",
    "\n",
    "demo, 改造成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of rbf is : 1.000000\n",
      "The score of linear is : 1.000000\n",
      "The score of poly is : 0.933333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split as ts\n",
    "\n",
    "#import our data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "#split the data to  7:3\n",
    "X_train,X_test,y_train,y_test = ts(X,y,test_size=0.3)\n",
    "\n",
    "# select different type of kernel function and compare the score\n",
    "\n",
    "# kernel = 'rbf'\n",
    "clf_rbf = svm.SVC(kernel='rbf')\n",
    "clf_rbf.fit(X_train,y_train)\n",
    "score_rbf = clf_rbf.score(X_test,y_test)\n",
    "print(\"The score of rbf is : %f\"%score_rbf)\n",
    "\n",
    "# kernel = 'linear'\n",
    "clf_linear = svm.SVC(kernel='linear')\n",
    "clf_linear.fit(X_train,y_train)\n",
    "score_linear = clf_linear.score(X_test,y_test)\n",
    "print(\"The score of linear is : %f\"%score_linear)\n",
    "\n",
    "# kernel = 'poly'\n",
    "clf_poly = svm.SVC(kernel='poly')\n",
    "clf_poly.fit(X_train,y_train)\n",
    "score_poly = clf_poly.score(X_test,y_test)\n",
    "print(\"The score of poly is : %f\"%score_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import random\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "import numpy\n",
    "\n",
    "#调整了格式，一行是一条数据\n",
    "def inputdata(filename):\n",
    "    f = open(filename,'r')\n",
    "    linelist = f.readlines()\n",
    "    return linelist\n",
    "\n",
    "def splitset(trainset,testset):\n",
    "    train_words = []\n",
    "    train_tags = []\n",
    "    test_words = []\n",
    "    test_tags = []\n",
    "    for i in trainset:\n",
    "        i = i.strip()\n",
    "        # index = i.index(':')\n",
    "        train_words.append(i[:-2])\n",
    "        # print i\n",
    "        train_tags.append(int(i[-1]))\n",
    "\n",
    "    for i in testset:\n",
    "        i = i.strip()\n",
    "        # index = i.index(':')\n",
    "        test_words.append(i[:-2])\n",
    "        # print i\n",
    "        test_tags.append(int(i[-1]))\n",
    "\n",
    "    return train_words,train_tags,test_words,test_tags\n",
    "\n",
    "#完成打开文件后的准备工作\n",
    "\n",
    "comma_tokenizer = lambda x: jieba.cut(x, cut_all=True)\n",
    "\n",
    "def tfvectorize(train_words,test_words):\n",
    "    v = TfidfVectorizer(tokenizer=comma_tokenizer,binary = False, decode_error = 'ignore',stop_words = 'english')\n",
    "    train_data = v.fit_transform(train_words)\n",
    "    test_data = v.transform(test_words)\n",
    "    return train_data,test_data\n",
    "\n",
    "#按比例划分训练集与测试集\n",
    "def splitDataset(dataset,splitRatio):\n",
    "    trainSize = int(len(dataset)*splitRatio)\n",
    "    trainSet = []\n",
    "    copy = dataset\n",
    "    while len(trainSet)<trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return trainSet,copy\n",
    "\n",
    "#得到准确率和召回率\n",
    "def evaluate(actual, pred):\n",
    "    m_precision = metrics.precision_score(actual, pred,average='macro')\n",
    "    m_recall = metrics.recall_score(actual,pred,average='macro')\n",
    "    print 'precision:{0:.3f}'.format(m_precision)\n",
    "    print 'recall:{0:0.3f}'.format(m_recall)\n",
    "\n",
    "#创建svm分类器\n",
    "def train_clf(train_data, train_tags):\n",
    "    clf = svm.SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=None, degree=3,\n",
    "                  gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "                  tol=0.001, verbose=False)\n",
    "    clf.fit(train_data, numpy.asarray(train_tags))\n",
    "\n",
    "    return clf\n",
    "\n",
    "def covectorize(train_words,test_words):\n",
    "    v = CountVectorizer(tokenizer=comma_tokenizer,binary = False, decode_error = 'ignore',stop_words = 'english')\n",
    "    train_data = v.fit_transform(train_words)\n",
    "    test_data = v.transform(test_words)\n",
    "    return train_data,test_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    linelist = inputdata('data/newdata.txt')\n",
    "    # for i in linelist:\n",
    "    #     print i.decode('utf-8')\n",
    "\n",
    "    # 划分成两个list\n",
    "    trainset, testset = splitDataset(linelist, 0.65)\n",
    "    # for i in trainset:\n",
    "    #     print i.decode('utf-8')\n",
    "    print 'train number:', len(trainset)\n",
    "    print 'test number:', len(testset)\n",
    "\n",
    "    train_words, train_tags, test_words, test_tags = splitset(trainset, testset)\n",
    "    # for i in train_words:\n",
    "    #     print i\n",
    "    # for i in train_tags:\n",
    "    #     print i\n",
    "    # for i in numpy.asarray(train_tags):\n",
    "    #     print i\n",
    "    # for i in test_words:\n",
    "    #     print i\n",
    "    # for i in test_tags:\n",
    "    #     print i\n",
    "\n",
    "\n",
    "    # train_data, test_data = tfvectorize(train_words, test_words)\n",
    "    train_data, test_data = covectorize(train_words, test_words)\n",
    "    # for i in test_data:\n",
    "    #     print i\n",
    "\n",
    "    clf = train_clf(train_data,train_tags)\n",
    "\n",
    "    re =  clf.predict(test_data)\n",
    "    # print re\n",
    "    evaluate(numpy.asarray(test_tags),re)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
